\begin{thebibliography}{}

\bibitem{girshick2015fast}
Girshick R. (2015). Fast r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 1440-1448).

\bibitem{krizhevsky2012imagenet}
Krizhevsky A., Sutskever I., \& Hinton G. E. (2012). Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25.

\bibitem{amodei2016deep}
Amodei D., Ananthanarayanan S., Anubhai R., Bai J., Battenberg E., Case C., ... \& Zhu Z. (2016, June). Deep speech 2: End-to-end speech recognition in english and mandarin. In International conference on machine learning (pp. 173-182). PMLR.

\bibitem{deng2018deep}
Deng L., \& Liu Y. (Eds.). (2018). Deep learning in natural language processing. Springer.

\bibitem{ortis2019overview}
Ortis A., Farinella G. M., \& Battiato S. (2019). An Overview on Image Sentiment Analysis: Methods, Datasets and Current Challenges. ICETE (1), 296-306.

\bibitem{carrara2018picture}
Carrara F., Esuli A., Fagni T., Falchi F., \& Moreo Fernández A. (2018). Picture it in your mind: Generating high level visual representations from textual descriptions. Information Retrieval Journal, 21, 208-229.

\bibitem{szegedy2013intriguing}
Szegedy C., Zaremba W., Sutskever I., Bruna J., Erhan D., Goodfellow I., \& Fergus R. (2013). Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199.

\bibitem{goodfellow2014explaining}
Goodfellow I. J., Shlens J., \& Szegedy C. (2014). Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572.

\bibitem{carlini2017towards}
Carlini N., \& Wagner D. (2017, May). Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp) (pp. 39-57). Ieee.

\bibitem{dong2018boosting}
Dong Y., Liao F., Pang T., Su H., Zhu J., Hu X., \& Li J. (2018). Boosting adversarial attacks with momentum. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 9185-9193).

\bibitem{kurakin2016adversarial}
Kurakin A., Goodfellow I. J., \& Bengio S. (2018). Adversarial examples in the physical world. In Artificial intelligence safety and security (pp. 99-112). Chapman and Hall/CRC.

\bibitem{liu2016delving}
Liu Y., Chen X., Liu C., \& Song D. (2016). Delving into transferable adversarial examples and black-box attacks. arXiv preprint arXiv:1611.02770.

\bibitem{papernot2017practical}
Papernot N., McDaniel P., Goodfellow I., Jha S., Celik Z. B., \& Swami A. (2017, April). Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on computer and communications security (pp. 506-519).

\bibitem{li2019scene}
Li C. Y., Shamsabadi A. S., Sanchez-Matilla R., Mazzon R., \& Cavallaro A. (2019, May). Scene privacy protection. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2502-2506). IEEE.

\bibitem{karras2019style}
Karras T., Laine S., \& Aila T. (2019). A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 4401-4410).

\bibitem{dabouei2019fast}
Dabouei A., Soleymani S., Dawson J., \& Nasrabadi N. (2019, January). Fast geometrically-perturbed adversarial faces. In 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) (pp. 1979-1988). IEEE.

\bibitem{gu2014towards}
Gu S., \& Rigazio L. (2014). Towards deep neural network architectures robust to adversarial examples. arXiv preprint arXiv:1412.5068.

\bibitem{madry2017towards}
Madry A., Makelov A., Schmidt L., Tsipras D., \& Vladu A. (2017). Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083.

\bibitem{papernot2016distillation}
Papernot N., McDaniel P., Wu X., Jha S., \& Swami A. (2016, May). Distillation as a defense to adversarial perturbations against deep neural networks. In 2016 IEEE symposium on security and privacy (SP) (pp. 582-597). IEEE.

\bibitem{rozsa2016adversarial}
Rozsa A., Rudd E. M., \& Boult T. E. (2016). Adversarial diversity and hard positive generation. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops (pp. 25-32).

\bibitem{carlini2017adversarial}
Carlini N., \& Wagner D. (2017, November). Adversarial examples are not easily detected: Bypassing ten detection methods. In Proceedings of the 10th ACM workshop on artificial intelligence and security (pp. 3-14).

\bibitem{grosse2017statistical}
Grosse K., Manoharan P., Papernot N., Backes M., \& McDaniel P. (2017). On the (statistical) detection of adversarial examples. arXiv preprint arXiv:1702.06280.

\bibitem{metzen2017detecting}
Metzen J. H., Genewein T., Fischer V., \& Bischoff B. (2017). On detecting adversarial perturbations. arXiv preprint arXiv:1702.04267.

\bibitem{gong2017adversarial}
Gong Z., \& Wang W. (2023, June). Adversarial and clean data are not twins. In Proceedings of the Sixth International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (pp. 1-5).

\bibitem{bhagoji2017dimensionality}
Bhagoji A. N., Cullina D., \& Mittal P. (2017). Dimensionality reduction as a defense against evasion attacks on machine learning classifiers. arXiv preprint arXiv:1704.02654, 2(1).

\bibitem{li2017adversarial}
Li X., \& Li F. (2017). Adversarial examples detection in deep networks with convolutional filter statistics. In Proceedings of the IEEE international conference on computer vision (pp. 5764-5772).

\bibitem{sadu2021defense}
Sadu C., \& Das P. K. (2021, December). A defense method against facial adversarial attacks. In TENCON 2021-2021 IEEE Region 10 Conference (TENCON) (pp. 459-463). IEEE.

\bibitem{biggio2013evasion}
Biggio B., Corona I., Maiorca D., Nelson B., Šrndić N., Laskov P., ... \& Roli F. (2013). Evasion attacks against machine learning at test time. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part III 13 (pp. 387-402). Springer Berlin Heidelberg.

\bibitem{moosavi2016deepfool}
Moosavi-Dezfooli S. M., Fawzi A., \& Frossard P. (2016). Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2574-2582).

\bibitem{papernot2016limitations}
Papernot N., McDaniel P., Jha S., Fredrikson M., Celik Z. B., \& Swami A. (2016, March). The limitations of deep learning in adversarial settings. In 2016 IEEE European symposium on security and privacy (EuroS\&P) (pp. 372-387). IEEE.

\bibitem{chen2017zoo}
Chen P. Y., Zhang H., Sharma Y., Yi J., \& Hsieh C. J. (2017, November). Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM workshop on artificial intelligence and security (pp. 15-26).

\bibitem{ilyas2018black}
Ilyas A., Engstrom L., Athalye A., \& Lin J. (2018, July). Black-box adversarial attacks with limited queries and information. In International conference on machine learning (pp. 2137-2146). PMLR.

\bibitem{alzantot2019genattack}
Alzantot M., Sharma Y., Chakraborty S., Zhang H., Hsieh C. J., \& Srivastava M. B. (2019, July). Genattack: Practical black-box attacks with gradient-free optimization. In Proceedings of the genetic and evolutionary computation conference (pp. 1111-1119).

\bibitem{xiao2018generating}
Xiao C., Li B., Zhu J. Y., He W., Liu M., \& Song D. (2018). Generating adversarial examples with adversarial networks. arXiv preprint arXiv:1801.02610.

\bibitem{goodfellow2014generative}
Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., ... \& Bengio Y. (2014). Generative adversarial nets. Advances in neural information processing systems, 27.



\bibitem{deb2020advfaces}
Deb D., Zhang J., \& Jain A. K. (2019). Advfaces: Adversarial face synthesis. arXiv preprint arXiv:1908.05008.

\bibitem{qiu2020semanticadv}
Qiu H., Xiao C., Yang L., Yan X., Lee H., \& Li B. (2020). Semanticadv: Generating adversarial examples via attribute-conditioned image editing. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIV 16 (pp. 19-37). Springer International Publishing.

\bibitem{xu2020adversarial}
Xu H., Ma Y., Liu H. C., Deb D., Liu H., Tang J. L., \& Jain A. K. (2020). Adversarial attacks and defenses in images, graphs and text: A review. International Journal of Automation and Computing, 17, 151-178.

\bibitem{hendrycks2016early}
Hendrycks D., \& Gimpel K. (2016). Early methods for detecting adversarial images. arXiv preprint arXiv:1608.00530.

\bibitem{massoli2021detection}
Massoli F. V., Carrara F., Amato G., \& Falchi F. (2021). Detection of face recognition adversarial attacks. Computer Vision and Image Understanding, 202, 103103.

\bibitem{agarwal2018image}
Agarwal A., Singh R., Vatsa M., \& Ratha N. (2018, October). Are image-agnostic universal adversarial perturbations for face recognition difficult to detect?. In 2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS) (pp. 1-7). IEEE.

\bibitem{xie2019feature}
Xie C., Wu Y., Maaten L. V. D., Yuille A. L., \& He K. (2019). Feature denoising for improving adversarial robustness. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 501-509).

\bibitem{mustafa2019image}
Mustafa A., Khan S. H., Hayat M., Shen J., \& Shao L. (2019). Image super-resolution as a defense against adversarial attacks. IEEE Transactions on Image Processing, 29, 1711-1724.

\bibitem{tomasi1998bilateral}
Tomasi C., \& Manduchi R. (1998, January). Bilateral filtering for gray and color images. In Sixth international conference on computer vision (IEEE Cat. No. 98CH36271) (pp. 839-846). IEEE.

\bibitem{kim2016accurate}
Kim J., Lee J. K., \& Lee K. M. (2016). Accurate image super-resolution using very deep convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1646-1654).

\bibitem{kim2016deeply}
Kim J., Lee J. K., \& Lee K. M. (2016). Deeply-recursive convolutional network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1637-1645).

\bibitem{lim2017enhanced}
Lim B., Son S., Kim H., Nah S., \& Mu Lee K. (2017). Enhanced deep residual networks for single image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops (pp. 136-144).

\bibitem{agarwal2017swapped}
Agarwal A., Singh R., Vatsa M., \& Noore A. (2017, October). Swapped! digital face presentation attack detection via weighted local magnitude pattern. In 2017 IEEE International Joint Conference on Biometrics (IJCB) (pp. 659-665). IEEE.

\bibitem{liu2015faceattributes}
Liu Z., Luo, P., Wang X., \& Tang X. (2015). Deep learning face attributes in the wild. In Proceedings of the IEEE international conference on computer vision (pp. 3730-3738).

\bibitem{krizhevsky2009learning}
 Krizhevsky A., \& Hinton G. (2009). Learning multiple layers of features from tiny images.
 
\bibitem{mnist}
LeCun Y. (1998). The MNIST database of handwritten digits. http://yann. lecun. com/exdb/mnist/.

\bibitem{ImageNet}
Deng J., Dong W., Socher R., Li L. J., Li,K., \& Fei-Fei L. (2009, June). Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition (pp. 248-255). Ieee.

\bibitem{Su}
Su J., Vargas D. V., \& Sakurai K. (2019). One pixel attack for fooling deep neural networks. IEEE Transactions on Evolutionary Computation, 23(5), 828-841.

\bibitem{pasc}
Beveridge J. R., Phillips P. J., Bolme D. S., Draper B. A., Givens G. H., Lui Y. M., ... \& Cheng S. (2013, September). The challenge of face recognition from digital point-and-shoot cameras. In 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS) (pp. 1-8). IEEE.

\bibitem{multi}
Gross R., Matthews I., Cohn J., Kanade T., \& Baker S. (2010). Multi-pie. Image and vision computing, 28(5), 807-813.

\bibitem{meds}
Founds A. P., Orlans N., Genevieve W., \& Watson C. I. (2011). Nist special databse 32-multiple encounter dataset ii (meds-ii).

\bibitem{Hyun2018}
Kwon H., Kim Y., Park K. W., Yoon H., \& Choi D. (2018). Friend-safe evasion attack: An adversarial example that is correctly recognized by a friendly classifier. computers \& security, 78, 380-397.

\bibitem{Lin2021}
Lin H., Wo Y., Wu Y., Meng K., \& Han G. (2021). Robust source camera identification against adversarial attacks. Computers \& Security, 100, 102079.

\bibitem{Liu2021}
Liu J., \& Jin Y. (2021). Multi-objective search of robust neural architectures against multiple types of adversarial attacks. Neurocomputing, 453, 73-84.

\bibitem{Wang2020}
Wang Y., Wang K., Zhu Z., \& Wang F. Y. (2020). Adversarial attacks on Faster R-CNN object detector. Neurocomputing, 382, 87-95.

\bibitem{Chen2020}
Chen S., He Z., Sun C., Yang J., \& Huang X. (2020). Universal adversarial attack on attention and the resulting dataset damagenet. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(4), 2188-2197.

\bibitem{Liu2023}
Liu J., Lu B., Xiong M., Zhang T., \& Xiong H. (2023). Low frequency sparse adversarial attack. Computers \& Security, 132, 103379.

\bibitem{He2023}
He X., Li Y., Qu H., \& Dong J. (2023). Improving transferable adversarial attack via feature-momentum. Computers \& Security, 128, 103135.

\bibitem{Survey2021}
Chakraborty A., Alam M., Dey V., Chattopadhyay A., \& Mukhopadhyay D. (2021). A survey on adversarial attacks and defences. CAAI Transactions on Intelligence Technology, 6(1), 25-45.

\bibitem{Murali2023}
Puttagunta M. K., Ravi S., \& Nelson Kennedy Babu C. (2023). Adversarial examples: attacks and defences on medical deep learning systems. Multimedia Tools and Applications, 1-37.

\bibitem{Teng2022}
Long T., Gao Q., Xu L., \& Zhou Z. (2022). A survey on adversarial attacks in computer vision: Taxonomy, visualization and future directions. Computers \& Security, 102847.

%\bibitem{Mustafa2020}
%Mustafa A., Khan S. H., Hayat M., Shen J., \& Shao L. (2019). Image super-resolution as a defense against adversarial attacks. IEEE Transactions on Image Processing, 29, 1711-1724.

\bibitem{Gabor2023}
Szűcs G., \& Kiss R. (2023). 2N labeling defense method against adversarial attacks by filtering and extended class label set. Multimedia Tools and Applications, 82(11), 16717-16740.

\bibitem{Ashish2023}
Bajaj A., \& Vishwakarma D. K. (2023). A state-of-the-art review on adversarial machine learning in image classification. Multimedia Tools and Applications, 1-66.

\bibitem{Ali2021}
Ahmadi M. A., Dianat R., \& Amirkhani H. (2021). An adversarial attack detection method in deep neural networks based on re-attacking approach. Multimedia Tools and Applications, 80, 10985-11014.

\bibitem{deng2021libre} Deng, Z., Yang, X., Xu, S., Su, H., \& Zhu, J. (2021). Libre: A practical bayesian approach to adversarial detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 972-982).

\bibitem{liu2019sbd} Liu, J., Zhang, W., Zhang, Y., Hou, D., Liu, Y., Zha, H., \& Yu, N. (2019). Detection based defense against adversarial examples from the steganalysis point of view. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4825-4834).

\bibitem{moayeri2021} Moayeri, M., \& Feizi, S. (2021). Sample efficient detection and classification of adversarial attacks via self-supervised embeddings. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 7677-7686).

\bibitem{voc2007}Everingham, M., Van Gool, L., Williams, C. K., Winn, J., \& Zisserman, A. (2008). The pascal visual object classes challenge 2007 (voc 2007) results (2007).

\end{thebibliography}

